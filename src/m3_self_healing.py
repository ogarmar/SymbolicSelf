# src/m3_self_healing.py â€” MÃ“DULO 3: Self-Healing Diagnostician
"""
Detecta degradaciÃ³n del modelo (ataques adversariales o concept drift)
analizando los sÃ­mbolos emergentes y aplica estrategias de healing.

Pipeline:
    1. Establecer baseline simbÃ³lico (estado "saludable")
    2. Comparar nuevos sÃ­mbolos vs baseline â†’ diagnÃ³stico dual:
       - Adversarial: caÃ­da brusca de estabilidad + alta entropÃ­a
       - Drift: cambio gradual en distribuciÃ³n de clusters
    3. Acciones de healing segÃºn diagnÃ³stico

Referencia: Self-Healing Machine Learning (SHML) paper.
"""

from __future__ import annotations

import logging
from dataclasses import dataclass
from enum import Enum
from typing import TYPE_CHECKING

import numpy as np

from src.config import (
    ADVERSARIAL_STABILITY_THRESHOLD,
    DRIFT_STABILITY_THRESHOLD,
    ENTROPY_CHANGE_THRESHOLD,
)

if TYPE_CHECKING:
    from src.symbol_detector import SymbolDetector

logger = logging.getLogger(__name__)


class DegradationType(Enum):
    """Tipos de degradaciÃ³n detectables."""
    HEALTHY = "healthy"
    ADVERSARIAL = "adversarial"
    DRIFT = "drift"


@dataclass
class Diagnosis:
    """Resultado de un diagnÃ³stico de degradaciÃ³n."""
    status: DegradationType
    stability: float
    entropy_delta: float
    healing_action: str

    def __str__(self) -> str:
        icons = {
            DegradationType.HEALTHY: "âœ…",
            DegradationType.ADVERSARIAL: "ðŸ¦ ",
            DegradationType.DRIFT: "ðŸ“‰",
        }
        return (
            f"{icons[self.status]} {self.status.value.upper()} | "
            f"stability={self.stability:.3f} entropy_Î”={self.entropy_delta:.3f} | "
            f"action: {self.healing_action}"
        )


class SelfHealingEngine:
    """Motor de auto-diagnÃ³stico y healing para el pipeline SymbolicSelf.

    Compara sÃ­mbolos actuales contra un baseline saludable para detectar
    degradaciÃ³n por ataques adversariales o concept drift.
    """

    def __init__(self, detector: SymbolDetector) -> None:
        self.detector = detector
        self.baseline_symbols: np.ndarray | None = None
        self.history: list[Diagnosis] = []

    # â”€â”€ Baseline â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def establish_baseline(self, symbols: np.ndarray) -> np.ndarray:
        """Establece los sÃ­mbolos de referencia (estado saludable).

        Args:
            symbols: Array de cluster IDs extraÃ­dos de una respuesta conocida.

        Returns:
            Los mismos sÃ­mbolos (para encadenamiento).
        """
        self.baseline_symbols = symbols.copy()
        n_unique = len(set(symbols[symbols >= 0]))
        logger.info("Baseline establecido: %d sÃ­mbolos Ãºnicos.", n_unique)
        return self.baseline_symbols

    # â”€â”€ DiagnÃ³stico â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def diagnose(self, current_symbols: np.ndarray) -> Diagnosis:
        """DiagnÃ³stico dual: adversarial vs drift vs healthy.

        Args:
            current_symbols: SÃ­mbolos de la respuesta actual a evaluar.

        Returns:
            Diagnosis con tipo, mÃ©tricas y acciÃ³n recomendada.
        """
        if self.baseline_symbols is None:
            raise RuntimeError(
                "Llama a establish_baseline() antes de diagnosticar."
            )

        # â”€â”€ Estabilidad (1 - JSD baseline <-> actual) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        dist_base = self._symbol_distribution(self.baseline_symbols)
        dist_curr = self._symbol_distribution(current_symbols)
        p, q = self._align_distributions(dist_base, dist_curr)

        from scipy.spatial.distance import jensenshannon
        jsd_val = float(jensenshannon(p, q))
        stability = 1.0 - jsd_val

        # â”€â”€ Cambio de entropÃ­a â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        entropy_baseline = self._compute_entropy(self.baseline_symbols)
        entropy_current = self._compute_entropy(current_symbols)
        entropy_delta = entropy_current - entropy_baseline

        # â”€â”€ ClasificaciÃ³n â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if stability < ADVERSARIAL_STABILITY_THRESHOLD or entropy_delta > ENTROPY_CHANGE_THRESHOLD:
            diagnosis = Diagnosis(
                status=DegradationType.ADVERSARIAL,
                stability=stability,
                entropy_delta=entropy_delta,
                healing_action="PurificaciÃ³n manifold (InfoNCE) + reducir temperatura",
            )
        elif stability < DRIFT_STABILITY_THRESHOLD:
            diagnosis = Diagnosis(
                status=DegradationType.DRIFT,
                stability=stability,
                entropy_delta=entropy_delta,
                healing_action="LoRA incremental + symbol-preserving loss",
            )
        else:
            diagnosis = Diagnosis(
                status=DegradationType.HEALTHY,
                stability=stability,
                entropy_delta=entropy_delta,
                healing_action="Continuar self-polish normalmente",
            )

        self.history.append(diagnosis)
        logger.info("Diagnostico: %s", diagnosis)
        return diagnosis

    # â”€â”€ Utilidades de distribucion (evita circular import con SymbolDetector) â”€â”€

    @staticmethod
    def _symbol_distribution(symbols: np.ndarray) -> np.ndarray:
        """Convierte cluster IDs en distribucion de probabilidad normalizada."""
        valid = symbols[symbols >= 0]
        if len(valid) == 0:
            return np.array([1.0])
        max_id = int(valid.max()) + 1
        counts = np.bincount(valid, minlength=max_id).astype(float)
        total = counts.sum()
        if total == 0:
            return np.array([1.0])
        return counts / total

    @staticmethod
    def _align_distributions(p: np.ndarray, q: np.ndarray) -> tuple[np.ndarray, np.ndarray]:
        """Alinea dos distribuciones al mismo tamano (padding con 0)."""
        max_len = max(len(p), len(q))
        p_aligned = np.zeros(max_len)
        q_aligned = np.zeros(max_len)
        p_aligned[:len(p)] = p
        q_aligned[:len(q)] = q
        return p_aligned, q_aligned

    # â”€â”€ Entropia simbolica â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    @staticmethod
    def _compute_entropy(symbols: np.ndarray) -> float:
        """Calcula la entropÃ­a de Shannon de la distribuciÃ³n de sÃ­mbolos.

        Excluye ruido (cluster -1). Una entropÃ­a alta indica desorganizaciÃ³n
        en las activaciones internas â†’ posible ataque adversarial.
        """
        valid = symbols[symbols >= 0]
        if len(valid) == 0:
            return 0.0

        _, counts = np.unique(valid, return_counts=True)
        probs = counts / counts.sum()  # â† FIX: normalizar por total, no por nÂº categorÃ­as
        return float(-np.sum(probs * np.log2(probs + 1e-10)))

    # â”€â”€ SimulaciÃ³n (para testing) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def simulate_degradation(
        self,
        degradation_type: str = "drift",
        severity: float = 0.8,
    ) -> np.ndarray:
        """Genera sÃ­mbolos degradados artificialmente para testing.

        Args:
            degradation_type: "adversarial" o "drift".
            severity: Intensidad de la degradaciÃ³n (0.0 a 2.0).

        Returns:
            Array de sÃ­mbolos degradados.
        """
        if self.baseline_symbols is None:
            raise RuntimeError("Establece baseline primero.")

        rng = np.random.default_rng(42)
        n_unique = len(set(self.baseline_symbols[self.baseline_symbols >= 0]))
        n_unique = max(n_unique, 2)  # Evitar divisiÃ³n por 0

        if degradation_type == "adversarial":
            # Reemplazar gran parte de los sÃ­mbolos con IDs completamente distintos
            degraded = self.baseline_symbols.copy()
            n_to_flip = int(len(degraded) * min(severity, 1.0) * 0.8)
            flip_indices = rng.choice(len(degraded), size=n_to_flip, replace=False)
            # Asignar IDs fuera del rango original â†’ Jaccard/JSD bajan
            new_ids = rng.integers(n_unique + 5, n_unique + 20, size=n_to_flip)
            degraded[flip_indices] = new_ids
        else:
            # Drift: shift gradual proporcional al nÂº de clusters
            shift = rng.integers(1, max(2, n_unique // 2), size=self.baseline_symbols.shape)
            degraded = self.baseline_symbols + shift

        return np.clip(degraded, -1, max(n_unique + 20, degraded.max()))
